name: CI/CD Pipeline for Microservices

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  workflow_dispatch: # Manuel tetikleme (GitHub arayüzünden çalıştırılabilir)

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true # Aynı işin eski sürümleri iptal edilir

env:
  DOCKERHUB_USERNAME: meyfcsalik # Buraya kendi Docker Hub kullanıcı adınızı girin

jobs:
  test-and-build:
    name: Test, Build and Push Docker Images
    runs-on: ubuntu-latest # GitHub tarafından barındırılan en son Ubuntu sürümü
    outputs:
      image_tag: ${{ steps.vars.outputs.sha_full }} # Tam commit SHA'sını çıktı olarak ver
      deploy_env: ${{ steps.set_env.outputs.DEPLOY_ENV }} # Dağıtım ortamını (production/staging) çıktı olarak ver
      image_tag_full_frontend: ${{ env.DOCKERHUB_USERNAME }}/frontend:${{ steps.set_env.outputs.DEPLOY_ENV }}-${{ steps.vars.outputs.sha_full }}
      image_tag_full_backend: ${{ env.DOCKERHUB_USERNAME }}/backend:${{ steps.set_env.outputs.DEPLOY_ENV }}-${{ steps.vars.outputs.sha_full }}
    services: # Testler için geçici MongoDB servisi başlat
      mongodb_test:
        image: mongo:6.0 # MongoDB 6.0 imajını kullan
        ports: [27017:27017] # 27017 portunu eşle
    steps:
      - name: Checkout Repository # Depoyu klonla
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # TruffleHog için tüm geçmişi çek

      - name: Set up Node.js with Cache v2 # Node.js 18 kur ve bağımlılıkları önbelleğe al
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: | # Hangi dosyaların önbellek bağımlılığı olduğunu belirt
            frontend/package-lock.json
            backend/package-lock.lock
      
      - name: Set Output Variables (Commit SHA) # Commit SHA'sını çıktı değişkeni olarak ayarla
        id: vars
        run: echo "sha_full=$(git rev-parse HEAD)" >> $GITHUB_OUTPUT

      - name: Determine Environment Name # Ortam adını (production/staging) belirle
        id: set_env
        run: |
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "DEPLOY_ENV=production" >> $GITHUB_OUTPUT
          else
            echo "DEPLOY_ENV=staging" >> $GITHUB_OUTPUT
          fi

      - name: Frontend - Install Dependencies & Lint # Ön uç bağımlılıklarını yükle ve lintle
        working-directory: ./frontend
        run: |
          npm ci
          npm run lint --if-present

      - name: Frontend - Run Tests # Ön uç testlerini çalıştır
        working-directory: ./frontend
        run: npm test --if-present -- --watchAll=false --coverage

      - name: Frontend - Build # Ön uç uygulamasını derle
        working-directory: ./frontend
        run: npm run build

      - name: Backend - Install Dependencies & Lint # Arka uç bağımlılıklarını yükle ve lintle
        working-directory: ./backend
        run: |
          npm ci
          npm run lint --if-present

      - name: Backend - Run Tests # Arka uç testlerini çalıştır
        working-directory: ./backend
        run: npm test --if-present -- --watchAll=false --coverage
        env:
          MONGO_URL: mongodb://localhost:27017/my-app_test # Testler için MongoDB URL'si (my-app olarak güncellendi)

      - name: Scan for secrets with TruffleHog # TruffleHog ile gizli anahtar taraması yap
        uses: trufflesecurity/trufflehog@main
        with:
          path: ./
          base: HEAD~1
          head: HEAD
          # TruffleHog aksiyonunun 'extra_args' veya 'exclude-patterns' parametreleriyle ilgili sürekli sorun yaşadığımız için
          # bu kısmı şimdilik kaldırıyoruz. Sadece 'continue-on-error: true' ile hatayı yoksayacağız.
        continue-on-error: true # Hata olsa bile pipeline'ın devam etmesini sağlar.

      - name: Log in to Docker Hub # Docker Hub'a giriş yap (yalnızca push olaylarında)
        if: github.event_name == 'push'
        uses: docker/login-action@v3
        with:
          username: ${{ env.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }} # GitHub Sırları'nda tanımlanmalı

      - name: Build and Push Frontend Docker Image # Ön uç Docker imajını derle ve gönder
        if: github.event_name == 'push'
        uses: docker/build-push-action@v5
        with:
          context: ./frontend
          file: ./frontend/Dockerfile
          push: true
          tags: ${{ env.DOCKERHUB_USERNAME }}/frontend:${{ steps.set_env.outputs.DEPLOY_ENV }}-${{ steps.vars.outputs.sha_full }}
          no-cache: true

      - name: Build and Push Backend Docker Image # Arka uç Docker imajını derle ve gönder
        if: github.event_name == 'push'
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          file: ./backend/Dockerfile
          push: true
          tags: ${{ env.DOCKERHUB_USERNAME }}/backend:${{ steps.set_env.outputs.DEPLOY_ENV }}-${{ steps.vars.outputs.sha_full }}
          no-cache: true

  deploy:
    name: Deploy to K3s and Run Security/E2E Tests via Ansible # K3s'e dağıtım ve güvenlik/E2E testleri
    needs: test-and-build # Önceki işin tamamlanmasını bekle
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop') # Belirli dallara push olaylarında tetikle
    runs-on: self-hosted # Kendinden barındırılan koşucu kullan
    environment: ${{ needs.test-and-build.outputs.deploy_env }} # Dağıtım ortamını ayarla
    steps:
      - name: Checkout Repository on Self-Hosted Runner # Depoyu kendinden barındırılan koşucuya klonla
        uses: actions/checkout@v4

      - name: Debug Print Current Working Directory # Hata ayıklama için dizin bilgilerini yazdır
        run: |
          pwd
          ls -F
          ls -F ansible/
          ls -F helm/my-app # Dizin adı 'my-app' olarak güncellendiği için düzeltildi

      - name: Set up Python and Install Ansible on Self-Hosted Runner # Python ve Ansible'ı kur (sanal ortam ile)
        run: |
          sudo apt-get update
          sudo apt-get install -y python3-venv # Sanal ortam için gerekli paketi yükle
          
          python3 -m venv .venv # Sanal ortam oluştur
          source .venv/bin/activate # Sanal ortamı etkinleştir
          
          pip install ansible openshift # Ansible ve gerekli modülleri sanal ortama kur

      - name: Configure SSH Private Key for Ansible # Ansible için SSH özel anahtarını yapılandır
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.K3S_SSH_PRIVATE_KEY }}" > ~/.ssh/k8s_cluster_key.pem
          chmod 600 ~/.ssh/k8s_cluster_key.pem # Anahtarın izinlerini ayarla (GitHub Sırları'nda tanımlanmalı)

      # --- KUBECONFIG YAPILANDIRMASI İÇİN DÜZELTİLEN VE DAHA DETAYLI LOGLAMA SAĞLAYAN ADIM ---
      - name: Kubeconfig'i Koşucuda Çek ve Yapılandır
        run: |
          mkdir -p ~/.kube || true # Dizin zaten varsa hata vermesin
          
          # K3s master düğümünüzdeki /home/mustafa/k3s.yaml konumundan kubeconfig dosyasını çekin.
          # Önceki adımda bu dosyayı buraya kopyalamıştınız ve izinlerini düzeltmiştiniz.
          # 'mustafa@192.168.0.60' yerine kendi SSH kullanıcı adınızı ve K3s master IP'nizi KESİNLİKLE kullanın.
          # scp komutunun başarısını kontrol edin ve loglayın.
          echo "Attempting to SCP kubeconfig from mustafa@192.168.0.60:/home/mustafa/k3s.yaml to ~/.kube/config"
          if scp -i ~/.ssh/k8s_cluster_key.pem -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            mustafa@192.168.0.60:/home/mustafa/k3s.yaml ~/.kube/config; then
            echo "SCP işlemi başarılı: Kubeconfig dosyası koşucuya kopyalandı."
          else
            echo "SCP işlemi BAŞARISIZ OLDU. Lütfen K3s sunucusundaki /home/mustafa/k3s.yaml dosyasının varlığını ve mustafa kullanıcısının okuma iznini kontrol edin. Bu hata pipeline'ı durduracaktır."
            exit 1 # Hata durumunda pipeline'ı durdur
          fi

          # Kubeconfig dosyası için doğru izinleri ayarla
          chmod 600 ~/.kube/config
          echo "Kubeconfig dosya izinleri 600 olarak ayarlandı."

          # Kubeconfig dosyasındaki sunucu adresini localhost/127.0.0.1'den K3s master IP'sine güncelleyin.
          # Koşucu K3s master'ının haricinde olduğu için bu çok önemlidir.
          # sed komutlarının başarısını kontrol edin ve loglayın.
          if sed -i "s/server: https:\/\/127.0.0.1:6443/server: https:\/\/192.168.0.60:6443/g" ~/.kube/config; then
            echo "Kubeconfig server adresi 127.0.0.1'den 192.168.0.60'a güncellendi."
          elif sed -i "s/server: https:\/\/localhost:6443/server: https:\/\/192.168.0.60:6443/g" ~/.kube/config; then
            echo "Kubeconfig server adresi localhost'tan 192.168.0.60'a güncellendi."
          else
            echo "UYARI: Kubeconfig dosyasında 127.0.0.1 veya localhost sunucu adresi bulunamadı/güncellenemedi. Kubeconfig dosyası zaten doğru IP'yi içeriyor olabilir veya manuel müdahale gerekebilir."
          fi

          # Hata ayıklama çıktısı: Kubeconfig'in bazı kısımlarını yazdır (hassas verileri gizleyerek)
          echo "--- Kubeconfig dosyası oluşturuldu ve güncellendi ---"
          cat ~/.kube/config | grep -v "client-certificate-data\|client-key-data\|certificate-authority-data" || true
          echo "-----------------------------------------"
      # --- KUBECONFIG ADIMININ SONU ---

      - name: Create Ansible Inventory File on Runner # Ansible envanter dosyasını koşucu üzerinde oluştur
        run: |
          mkdir -p ansible # Eğer silinmişse tekrar oluştur (emin olmak için)
          rm -f ansible/k3s-cluster.ini # Eski dosyayı temizle
          
          # printf kullanarak envanter dosyasını kontrollü bir şekilde yaz.
          # Lütfen ANSIBLE KULLANICINIZI BURADA KENDİ DOĞRU KULLANICI ADINIZLA DEĞİŞTİRİN (örn. 'mustafa', 'root', 'ubuntu' vb.)
          printf "[k3s_cluster]\n" > ansible/k3s-cluster.ini
          printf "192.168.0.60 ansible_user=mustafa ansible_ssh_private_key_file=~/.ssh/k8s_cluster_key.pem\n" >> ansible/k3s-cluster.ini
          
          # Oluşturulan dosyayı doğrula ve loglara yaz (hata ayıklama için çok önemli)
          echo "--- Content of newly created k3s-cluster.ini ---"
          cat ansible/k3s-cluster.ini
          echo "------------------------------------------------"
          ls -l ansible/k3s-cluster.ini # Dosya izinlerini ve varlığını kontrol et
          chmod 644 ansible/k3s-cluster.ini # Okunabilir olduğundan emin ol

      - name: Verify Inventory Creation & Location # Envanter oluşturma ve konumunu doğrulama adımı
        run: |
          echo "--- Checking inventory file after creation ---"
          pwd # Mevcut çalışma dizinini tekrar yazdır
          ls -l ansible/k3s-cluster.ini # Dosyanın varlığını ve izinlerini kontrol et
          cat ansible/k3s-cluster.ini # İçeriğini tekrar logla
          echo "----------------------------------------------"

      - name: Provide Ansible Vault Password # Ansible Vault parolasını sağla
        run: |
          echo "${{ secrets.ANSIBLE_VAULT_PASSWORD }}" > vault_pass.txt # GitHub Sırları'nda tanımlanmalı

      - name: Run Ansible Playbook for Deployment, Security and E2E Tests # Ansible playbook'unu çalıştır (dağıtım, güvenlik ve E2E testleri için)
        shell: bash # Sanal ortamı etkinleştirmek için shell'i belirt
        run: |
          source .venv/bin/activate # Sanal ortamı yeniden etkinleştir (önceki adımın shell'i kapandığı için)
          
          # --- Ansible Envanter ve Bağlantı Hata Ayıklama Başlangıcı ---
          echo "--- Debugging Ansible Inventory and Connectivity ---"
          which ansible # Ansible'ın nerede olduğunu göster (sanal ortamdaki)
          ansible --version # Ansible sürümünü göster
          echo "Contents of ansible/k3s-cluster.ini:"
          cat ansible/k3s-cluster.ini # Envanter dosyasının içeriğini göster
          echo "Ansible Inventory List (should show k8s_cluster and master host):"
          ansible-inventory -i ansible/k3s-cluster.ini --list # Ansible'ın envanteri nasıl gördüğünü göster
          echo "Testing SSH connectivity to master (192.168.0.60):"
          # SSH bağlantısını test et (StrictHostKeyChecking=no ve UserKnownHostsFile=/dev/null ile ilk bağlantı hatalarını önle)
          ssh -i ~/.ssh/k8s_cluster_key.pem -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null mustafa@192.168.0.60 'echo Connected && exit' || echo "SSH connection to 192.168.0.60 failed."
          echo "--- End Debugging Ansible Inventory and Connectivity ---"

          # Frontend ve Backend imaj etiketlerini Bash değişkenlerine al
          FRONTEND_FULL_TAG="${{ needs.test-and-build.outputs.image_tag_full_frontend }}"
          BACKEND_FULL_TAG="${{ needs.test-and-build.outputs.image_tag_full_backend }}" 

          # Bash string manipülasyonu ile sadece etiketi al (ör: "repo/image:tag" -> "tag")
          FRONTEND_ONLY_TAG="${FRONTEND_FULL_TAG##*:}"
          BACKEND_ONLY_TAG="${BACKEND_FULL_TAG##*:}"

          # ansible-playbook komutunu çalıştır.
          # Her satır sonunda '\' varsa, sonrasında boşluk olmadığından emin ol.
          # Son '--extra-vars' satırının sonunda '\' OLMAMALI ve boşluk OLMAMALI.
          ansible-playbook ansible/playbook.yaml \
            -i ansible/k3s-cluster.ini \
            --vault-password-file vault_pass.txt \
            --extra-vars "helm_release_name=my-app" \
            --extra-vars "k8s_namespace=default" \
            --extra-vars "helm_chart_path=../helm/my-app/" \
            --extra-vars "frontend_image_repo=${{ env.DOCKERHUB_USERNAME }}/frontend" \
            --extra-vars "frontend_image_tag=${FRONTEND_ONLY_TAG}" \
            --extra-vars "backend_image_repo=${{ env.DOCKERHUB_USERNAME }}/backend" \
            --extra-vars "backend_image_tag=${BACKEND_ONLY_TAG}" \
            --extra-vars "app_domain=my-app-${{ needs.test-and-build.outputs.deploy_env }}.example.com" \
            --extra-vars "deploy_env_name=${{ needs.test-and-build.outputs.deploy_env }}"
        env:
          ANSIBLE_HOST_KEY_CHECKING: 'False' # SSH host anahtarı doğrulamayı kapat (daha kolay hata ayıklama için)

      - name: Clean up Vault Password File # Vault parola dosyasını temizle
        if: always() # Önceki adımlar başarısız olsa bile çalışır
        run: rm -f vault_pass.txt
